{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TEST CASE LEADERBOARD: performance on specific datasets and their computational efficiency**\n",
    "\n",
    "    1. Load the data from `sentiment_test_cases.csv`.\n",
    "\n",
    "    2. Model Selection        \n",
    "\n",
    "        * Accuracy, Precision, Recall, \n",
    "        * Weighted F1 Score For Multi Classication Models\n",
    "        * Computational Efficiency\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "# Suppress the warning message\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sentiment_mapping = {\n",
    "            \"positive\": [\"positive\", \"POS\", \"LABEL_2\"],\n",
    "            \"neutral\": [\"neutral\", \"NEU\", \"LABEL_1\"],\n",
    "            \"negative\": [\"negative\", \"NEG\", \"LABEL_0\"]\n",
    "        }\n",
    "    \n",
    "    def standardize_sentiment_label(self, label):\n",
    "        \"\"\"\n",
    "        This function standardizes the sentiment label according to the specified mapping.\n",
    "        \n",
    "        :param label: The input sentiment label to standardize.\n",
    "        :return: The standardized sentiment label.\n",
    "        \"\"\"\n",
    "        \n",
    "        for key, value in self.sentiment_mapping.items():\n",
    "            if label.lower() in [x.lower() for x in value]:\n",
    "                return key\n",
    "        return label\n",
    "\n",
    "    def sentiment_analysis(self, df, path, model_selection_list):\n",
    "        \"\"\"\n",
    "        This function performs sentiment analysis on the input DataFrame using the specified models.\n",
    "        \n",
    "        :param df: The input DataFrame containing the text to analyze.\n",
    "        :param path: The path to the downloaded repository containing the models.\n",
    "        :param model_selection_list: A list of model names to use for sentiment analysis.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create an empty list to store the computational efficiency results\n",
    "        computational_efficiency = []\n",
    "\n",
    "        # Iterate over the list of models\n",
    "        for model_name in model_selection_list:\n",
    "            # Start the timer\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Define the path to the downloaded repository for the current model\n",
    "            repo_path = f\"{path}/{model_name}\"\n",
    "    \n",
    "            # Load the tokenizer and model\n",
    "            tokenizer = AutoTokenizer.from_pretrained(repo_path)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(repo_path)\n",
    "           \n",
    "            # Define a function to perform sentiment analysis on a single text\n",
    "            def analyze_text(text):\n",
    "                \"\"\"\n",
    "                This function performs sentiment analysis on a single text using the specified model.\n",
    "                \n",
    "                :param text: The input text to analyze.\n",
    "                :return: A tuple containing the predicted label and confidence score.\n",
    "                \"\"\"\n",
    "                \n",
    "                # Tokenize the input text\n",
    "                inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "                \n",
    "                # Make a prediction using the model\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                \n",
    "                # Get the predicted label and confidence score\n",
    "                predicted_label = outputs.logits.argmax(dim=-1).item()\n",
    "                confidence_score = outputs.logits.softmax(dim=-1).max().item()\n",
    "                \n",
    "                # Convert the predicted label to a string and standardize it\n",
    "                label_str = self.standardize_sentiment_label(model.config.id2label[predicted_label])\n",
    "                \n",
    "                return label_str, round(confidence_score * 100, 2)\n",
    "\n",
    "            # Apply the sentiment analysis function to each row of the input DataFrame\n",
    "            output_df = df.copy()\n",
    "            output_df[[\"model_output\", \"confidence_score\"]] = output_df[\"text\"].apply(lambda x: pd.Series(analyze_text(x)))\n",
    "\n",
    "            # Reorder the columns of the output DataFrame\n",
    "            output_df = output_df[[\"text\", \"expected_sentiment\", \"model_output\", \"confidence_score\"]]\n",
    "\n",
    "            # Save the resulting DataFrame to a CSV file\n",
    "            output_df.to_csv(f\"../dataset/output/output_{model_name}_sentiment_test.csv\", index=False)\n",
    "\n",
    "            # Stop the timer and calculate the elapsed time\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "\n",
    "            # Append the current model's computational efficiency to the list\n",
    "            computational_efficiency.append({\"model\": model_name, \"time\": elapsed_time})\n",
    "\n",
    "        # Convert the computational efficiency results to a DataFrame and save it to a CSV file\n",
    "        pd.DataFrame(computational_efficiency).to_csv(\"../dataset/output/computational_efficiency.csv\", index=False)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../dataset/test_dataset/sentiment_test_cases.csv')\n",
    "\n",
    "# Create a bar chart of the expected_sentiment column\n",
    "df['expected_sentiment'].value_counts().plot(kind='bar')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Expected Sentiment')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Define the path to the downloaded repository containing the models\n",
    "path = \"../models\"\n",
    "\n",
    "# Define the list of models to use for sentiment analysis\n",
    "model_selection_list = [\n",
    "    \"twitter-roberta-base-sentiment-latest\",\n",
    "    \"bertweet-base-sentiment-analysis\",\n",
    "    \"twitter-xlm-roberta-base-sentiment\",\n",
    "    \"twitter-roberta-base-sentiment\"\n",
    "]\n",
    "\n",
    "# Create an instance of SentimentAnalyzer and apply sentiment analysis to the input DataFrame using each model in the list\n",
    "analyzer = SentimentAnalyzer()\n",
    "analyzer.sentiment_analysis(df, path, model_selection_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the model `twitter-roberta-base-sentiment-latest`\n",
    "\n",
    "\n",
    "Generate final output requirements for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# List of files to be copied\n",
    "files_to_copy = ['output_twitter-roberta-base-sentiment-latest_sentiment_test.csv', 'computational_efficiency.csv', 'initial_benchmark.csv']\n",
    "\n",
    "src_dir = '../dataset/output'\n",
    "des_dir = '../results/output'\n",
    "\n",
    "# Create destination directory if it doesn't exist\n",
    "if not os.path.exists(des_dir):\n",
    "    os.makedirs(des_dir)\n",
    "\n",
    "# Copy specified files from source to destination\n",
    "for filename in files_to_copy:\n",
    "    src = os.path.join(src_dir, filename)\n",
    "    des = os.path.join(des_dir, filename)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, des)\n",
    "\n",
    "# Rename a specific file\n",
    "src = '../results/output/output_twitter-roberta-base-sentiment-latest_sentiment_test.csv'\n",
    "des = '../results/output/output_sentiment_test.csv'\n",
    "if os.path.exists(src):\n",
    "    os.rename(src, des)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
